Машинное обучение - это метод анализа данных, который автоматизирует построение аналитической модели. Это отрасль искусственного интеллекта, основанная на идее, что системы могут обучаться на основе данных, выявлять закономерности и принимать решения с минимальным вмешательством человека. Растущие объемы и разнообразие доступных данных, относительно дешевая и мощная вычислительная техника, доступные хранилища для хранения данных - все эти факторы делают машинное обучение доступным сегодня, они позволяют быстро и автоматизировано производить модели, которые могут анализировать более объемные и сложные данные и обеспечивать быстрые и более точные результаты даже на очень больших объемах. А создание точных моделей в свою очередь gозволяет делать прогнозы, выявлять закономерности, а также даёт организациям больше шансов определить выгодные возможности или избежать неизвестных рисков. В этой книге рассказывается о применении методов машинного обучения для анализа текста с использованием следующих библиотек на Python: Scikit-Learn, NLTK, Gensim, spaCy, NetworkX, Yellowbrick. Прикладной характер книги предполагает акцентирование внимания не на академической лингвистике или статистических моделях, а на эффективном развертывании моделей, обученных на тексте внутри приложения. Предлагаемая в книге модель анализа текста напрямую связана с процессом машинного обучения — поиска модели, состоящей из признаков, алгоритма и гиперпараметров, которая давала бы лучшие результаты на обучающих данных, с целью оценки неизвестных данных. Этот процесс начинается с создания обучающего набора данных, который в сфере анализа текстов называют корпусом. Затем исследуются методы извлечения признаков и предварительной обработки для представления текста в виде числовых данных, понятных моделям машинного обучения. Далее идёт изучение приемов классификации и кластеризации текста, рассказ о которых завершает первые главы книги. В последующих главах основное внимание уделяется расширению моделей более богатыми наборами признаков и созданию приложений анализа текстов. Сначала показывается, как можно представить и внедрить контекст в виде признаков, затем осуществляется преход к визуальной интерпретации для управления процессом выбора модели. Потом анализируются сложные отношения, извлекаемые из текста с применением приемов анализа графов. Впоследствии расширяется понятие синтаксического и семантического анализа текста. В заключение книги представляется практическое обсуждение приемов масштабирования анализа текста в многопроцессорных системах с применением Spark, и, наконец, рассматривается следующий этап анализа текста: глубокое обучение. Эта книга адресована программистам на Python, интересующимся применением методов обработки естественного языка и машинного обучения в своих программных продуктах. Не предполагается наличия у читателей книги специальных академических или математических знаний и вместо этого основное внимание уделяется инструментам и приемам, а не пространным объяснениям. В первую очередь в этой книге обсуждается анализ текстов на английском языке, поэтому читателям пригодится хотя бы базовое знание грамматических сущностей, таких как существительные, глаголы, наречия и прилагательные, и того, как они связаны между собой. Читатели, не имеющие опыта в машинном обучении и лингвистике, но обладающие навыками программирования на Python, не будут чувствовать себя потерянными при изучении понятий, которые представляются в книге. Бенджамин Бенгфорт (Benjamin Bengfort) — один из авторов книги, специалист в области data science. В настоящее время работает над докторской диссертацией в Университете штата Мериленд, где изучает машинное обучение и распределенные вычисления. Профессиональный программист по образованию, исследователь данных, Бенджамин часто пишет статьи, освещающие широкий круг вопросов — от обработки естественного языка до исследования данных на Python и применения Hadoop и Spark в аналитике. Д-р Ребекка Билбро (Dr Rebecca Bilbro) — один из авторов книги, специалист в области data science, программист на Python, учитель, лектор и автор статей. Специализируется на визуальной оценке результатов машинного обучения: от анализа признаков до выбора моделей и настройки гиперпараметров. Проводит исследования в области обработки естественного языка, построения семантических сетей, разрешения сущностей и обработки информации с большим количеством измерений. Как активный участник сообщества пользователей и разработчиков открытого программного обеспечения, Ребекка сотрудничает с другими разработчиками над такими проектами, как Yellowbrick (пакет на языке Python, целью которого является прогнозное моделирование на манер черного ящика). Тони Охеда (Tony Ojeda) — один из авторов книги, специалист в области data science, писатель и предприниматель с опытом оптимизации бизнесс-процессов и создания и внедрения инновационных приложений данных. Основал District Data Labs, консалтинговую фирму, специализирующуюся на корпоративных тренингах в области исследования данных и совместных исследованиях, где люди разных специальностей работают над интересными проектами, расширяют свои возможности и помогают друг другу стать более успешными исследователями данных. Также является сооснователем Data Community DC, профессиональной организации, поддерживающей и продвигающей исследователей данных и их работу. Имеет степень магистра финансов, полученную в Международном университете штата Флорида, и степень MBA. Обучался стратегии предпринимательства в Университете Де Поля в Чикаго. Данное учебное пособие подходит студентам и аспирантам для изучения базовых понятий и вопросов в сфере обработки текстов и их последующего анализа. В первой главе рассказывается про компьютерную лингвистику, какие задачи решает компьютерная лингвистика, этапы и модули обработки текстов, а также про сложности моделирования ЕЯ. Эта глава служит введением к книге, так как в ней рассматриваются основные термины компьютерной лингвистики, которые будут полезны в дальнейшем. Во второй и третьей главах затрагивается морфологический анализ текстов и извлечение информации из них. А именно делается обзор основных модулей морфологического анализа и методов хранения словарей. Помимо этого рассматривается машинное обучение в задачах извлечения информации, а также специфика таких задач и подходы к их решению. В конце книги – в четвёртой и пятой главах рассказывается про анализ тональности текстов, сложности такого анализа и про тематическое моделирование. Также говорится про автоматические методы анализа тональности и тестирование систем такого анализа. Большакова, Воронцов, Ефремова, Клышинский, Лукашевич, Сапин — авторы книги, специалисты в области data science. Сотрудники таких российских ВУЗов, как Московский государственный университет имени Ломоносова и НИУ "Высшая школа экономики кондидаты и доктора физико-математических наук. Данная статья посвящена обработке естественного языка, проблемам, которые могут возникнуть при такой обработке и математическим методам в анализе текстов. Проблемы обработки естественного языка. Обработка текстов, написанных на естественном языке, сопровождается рядом трудностей, которые отсутствуют при использовании в прикладных и теоретических задачах языка математики и логики. Связано это с некоторыми неоднозначностями, присущими естественным языкам. Полисемия – в различных контекстах одна и та же лексема может употребляться в разных (хотя и близких по смыслу) значениях. Синонимия – различные синтаксические единицы несут в себе схожий смысл. Омонимия – одна и та же синтаксическая единица может проявлять себя в двух совершенно различных значениях (например, в зависимости от связи с определенным актантом). Из описанных характерных черт естественных языков следует необходимость проведения тщательного анализа всего текста для однозначного устранения возможных неопределенностей. Поэтому особое внимание в книгах по анализу текстовых данных особое внимание уделяется семантическому анализу, который выполняет синтезирующую функцию накопленных синтаксических связей и лексем. Математические методы в анализе текстов. Существует схема обработки естественного языка, представляющая из себя пирамиду, которая состоит из четырёх слоев. Морфологический разбор (идентификация леммы исходной лексемы, проверка на наличие грамматических ошибок). Синтаксический анализ (определение частей речи синтаксических единиц, построение синтаксического дерева). Семантический анализ (разрешение синтаксических связей между единицами предложения, устранение возможных неоднозначностей в их употреблении). Прагматический анализ (разрешение связей между всеми предложениями текста, то есть нахождение дискурса). Синтаксический анализ, вероятно, является наиболее изученной отраслью компьютерной лингвистики. В статье представлены три подхода к его реализации, каждый из которых имеет свои преимущества и недостатки по сравнению в другими.